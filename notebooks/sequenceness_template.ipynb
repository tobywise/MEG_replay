{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replay in Aversive Environments - Sequenceness analysis\n",
    "\n",
    "#### _This is a template that will be parameterised and run via [Papermill](http://papermill.readthedocs.io/) for each subject_\n",
    "\n",
    "This notebook uses the classifer trained on the localiser data to detect spontaneous state reactivation during the planning and rest phases of the task.\n",
    "\n",
    "Analysis steps:\n",
    "\n",
    "1. Loading task data and classifier\n",
    "2. Applying the classifer to the task data to generate time X state reactivation probabilities matrices\n",
    "3. Running the GLM-based sequenceness estimation procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('..')\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, 'code')\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_predict\n",
    "from sklearn.externals import joblib\n",
    "import os\n",
    "import papermill as pm\n",
    "from state_prediction import *\n",
    "from sequenceness import *\n",
    "from utils import *\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "session_id = 'MG05513'  # ID of the scanning session\n",
    "output_dir = 'data/derivatives'  # Where the output data should go\n",
    "eye_tracking = True  # If True, eye-tracking measures will be used for exclusion of blink-related ICA components\n",
    "n_stim = 8  # Number of stimuli, including null\n",
    "shifts = [-5, 6]  # Additional timepoints to use as features\n",
    "max_lag = 40  # Maximum lag to use in sequencess analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_ids = pd.read_csv('subject_ids.csv', sep='\\t')\n",
    "behavioural_id = subject_ids.loc[subject_ids['meg'] == session_id]['behavioural'].values[0]\n",
    "localiser_stimuli_file = os.path.join('localiser/Data', [i for i in os.listdir('localiser/Data') if behavioural_id in i and 'stimuli' in i][0])\n",
    "task_stimuli_file = os.path.join('task/Data/behavioural/logs', [i for i in os.listdir('task/Data/behavioural/logs') if behavioural_id in i and 'stimuli' in i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stimuli(log_file):\n",
    "    with open(log_file, 'r') as f:\n",
    "        stimuli = f.read().split(',')\n",
    "    stimuli = [re.search('[0-9]{2}', i).group() for i in stimuli]\n",
    "    return stimuli\n",
    "\n",
    "def match_stimuli(localiser, task):\n",
    "    localiser_stimuli = get_stimuli(localiser)\n",
    "    task_stimuli = get_stimuli(task)\n",
    "    print(localiser_stimuli, task_stimuli)\n",
    "    new_idx = [localiser_stimuli.index(i) for i in task_stimuli]\n",
    "    return new_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_idx = match_stimuli(localiser_stimuli_file, task_stimuli_file) + [7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State detection\n",
    "\n",
    "### Load the classifier\n",
    "\n",
    "First we load the classifier that we previously trained on the localiser data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load(os.path.join(output_dir, 'classifier', 'sub-{0}_classifier.pkl').format(session_id)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the task data\n",
    "\n",
    "We're interested in the planning and rest phases so we'll select these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_epochs = mne.read_epochs(os.path.join(output_dir, 'preprocessing/task', 'sub-{0}_ses-01_task-AversiveLearningReplay_run-task_proc_ICA-epo.fif.gz').format(session_id))\n",
    "planning_epochs = task_epochs['planning']\n",
    "rest_epochs = task_epochs['rest']\n",
    "\n",
    "# Get the data as a numpy array, excluding non-MEG channels\n",
    "picks_meg = mne.pick_types(task_epochs.info, meg=True, ref_meg=False)\n",
    "planning_X = planning_epochs.get_data()[:, picks_meg, :] # MEG signals: n_epochs, n_channels, n_times\n",
    "rest_X = rest_epochs.get_data()[:, picks_meg, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isnan(planning_X).any() == False, \"Nans present in planning data\"\n",
    "assert np.isnan(rest_X).any() == False, \"Nans present in rest data\"\n",
    "assert np.isinf(planning_X).any() == False, \"Infs present in planning data\"\n",
    "assert np.isinf(rest_X).any() == False, \"Infs present in rest data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State detection\n",
    "\n",
    "Here we iterate over trials, reshape the data for each trial into the format `[n_trials, n_sensors, n_timepoints]`, where the first dimension is 1 and the final dimension is the timepoint of interest plus additional adjacent timepoints used as extra features, and finally and use the `predict_proba` method of the fitted classifier to get predicted state reactivation probabilities for every timepoint within the trial.\n",
    "\n",
    "\n",
    "This involves a lot of for loops and could probably be made far more efficient..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = joblib.load(os.path.join(output_dir, 'classifier', 'sub-{0}_pca.pkl').format(session_id)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# planning_X = pca.transform(planning_X)\n",
    "# rest_X = pca.transform(rest_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planning_state_reactivation = predict_states(planning_X, clf, shifts=shifts)\n",
    "assert np.isnan(planning_state_reactivation).any() == False, \"Nans present in planning state reactivation array\"\n",
    "assert np.isinf(planning_state_reactivation).any() == False, \"Infs present in planning state reactivation array\"\n",
    "\n",
    "rest_state_reactivation = predict_states(rest_X, clf, shifts=shifts)\n",
    "assert np.isnan(rest_state_reactivation).any() == False, \"Nans present in rest state reactivation array\"\n",
    "assert np.isinf(rest_state_reactivation).any() == False, \"Infs present in rest state reactivation array\"\n",
    "\n",
    "# # Save state probabilities\n",
    "np.save(os.path.join(output_dir, 'state_reactivation_arrays', 'planning', 'sub-{0}_planning_state_reactivation'.format(session_id)), planning_state_reactivation)\n",
    "np.save(os.path.join(output_dir, 'state_reactivation_arrays', 'rest', 'sub-{0}_rest_state_reactivation'.format(session_id)), rest_state_reactivation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planning_state_reactivation = planning_state_reactivation[..., correct_idx]\n",
    "rest_state_reactivation = rest_state_reactivation[..., correct_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to StateReactivation class\n",
    "rest_state_reactivation = StateReactivation(rest_state_reactivation)\n",
    "planning_state_reactivation = StateReactivation(planning_state_reactivation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert to StateReactivation class\n",
    "# planning_state_reactivation = StateReactivation(planning_X, clf)\n",
    "# rest_state_reactivation = StateReactivation(rest_X, clf)\n",
    "\n",
    "# planning_state_reactivation.predict_states(shifts=shifts)\n",
    "# assert np.isnan(planning_state_reactivation.reactivation_array).any() == False, \"Nans present in planning state reactivation array\"\n",
    "# assert np.isinf(planning_state_reactivation.reactivation_array).any() == False, \"Infs present in planning state reactivation array\"\n",
    "\n",
    "# rest_state_reactivation.predict_states(shifts=shifts)\n",
    "# assert np.isnan(rest_state_reactivation.reactivation_array).any() == False, \"Nans present in rest state reactivation array\"\n",
    "# assert np.isinf(rest_state_reactivation.reactivation_array).any() == False, \"Infs present in rest state reactivation array\"\n",
    "\n",
    "# # Save state probabilities\n",
    "# # np.save(os.path.join(output_dir, 'state_reactivation_arrays', 'planning', 'sub-{0}_planning_state_reactivation'.format(session_id)), planning_state_reactivation)\n",
    "# # np.save(os.path.join(output_dir, 'state_reactivation_arrays', 'rest', 'sub-{0}_rest_state_reactivation'.format(session_id)), rest_state_reactivation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot state detection probabilities\n",
    "\n",
    "We can plot these state X time arrays to view how states are reactivated over time on each trial.\n",
    "\n",
    "_This is commented out here as it's an interactive plot which takes a while to run/load and increases the size of the notebook_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # REST PHASE\n",
    "# plot_state_prob(rest_state_probabilities, 'Rest phase')\n",
    "\n",
    "# # PLANNING PHASE\n",
    "# plot_state_prob(planning_state_probabilities, 'Planning phase')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequenceness analysis\n",
    "\n",
    "After determining the state reactivation probabilities for each trial, we can submit this data to the sequenceness analysis. We use a GLM approach here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load transition matrix\n",
    "\n",
    "Here we load the transition matrix of the task, which is necessary for sequenceness analysis. We then subset this matrix to get the two branches of the task tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_matrix = np.loadtxt(r'task/Task_information/transition_matrix.txt')\n",
    "\n",
    "matrices = [transition_matrix]\n",
    "\n",
    "for n, i in enumerate([5, 6]):\n",
    "    matrices.append(select_path(transition_matrix, i))\n",
    "\n",
    "# Cross-state transitions for each stage\n",
    "v = np.zeros((7, 7))\n",
    "v[1, 2] = 1\n",
    "v2 = np.zeros((7, 7))\n",
    "v2[3, 4] = 1\n",
    "v3 = np.zeros((7, 7))\n",
    "v3[5, 6] = 1\n",
    "\n",
    "# Off-matrix transitions\n",
    "v4 = 1 - transition_matrix\n",
    "v5 = 1 - transition_matrix.T\n",
    "for i in range(7):\n",
    "    v4[i, :i+1] = 0\n",
    "    v5[:i+1, i] = 0\n",
    "\n",
    "# Cross-path transitions\n",
    "v6 = v + v2 + v3\n",
    "\n",
    "## two step\n",
    "v7 = np.zeros([7, 7])\n",
    "v7[1, 5] = 1\n",
    "v7[2, 6] = 1\n",
    "v8 = v7.T\n",
    "\n",
    "    \n",
    "matrices = matrices + [v, v2, v3, v4, v5, v6, v7, v8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the analysis for each trial\n",
    "\n",
    "This returns a dictionary with entries representing forwards and reverse sequenceness, along with the difference between the two.\n",
    "\n",
    "This is repeated for 1000 permuted transition matrices that share no transitions with the true matrix or its inverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permuted_matrices = generate_permuted_matrices(transition_matrix, n_permutations=20, n_transitions=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_matrices(pepermuted_matrices = generate_permuted_matrices(transition_matrix, n_permutations=20, n_transitions=3)rmuted_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rest_sequenceness, null_rest_sequenceness = rest_state_reactivation.get_sequenceness(max_lag, matrices, alpha=True, remove_first=True, permuted_matrices=permuted_matrices, constant=False)\n",
    "# planning_sequenceness, null_planning_sequenceness = planning_state_reactivation.get_sequenceness(max_lag, matrices, alpha=True, remove_first=True, permuted_matrices=permuted_matrices, constant=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rest_sequenceness_segments, _ = rest_state_reactivation.get_sequenceness_segments(max_lag, matrices, alpha=False, remove_first=False, permuted_matrices=[], constant=True, n_segments=5)\n",
    "# planning_sequenceness_segments, _ = planning_state_reactivation.get_sequenceness_segments(max_lag, matrices, alpha=False, remove_first=False, permuted_matrices=[], constant=True, n_segments=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(2, figsize=(6, 10), facecolor='white')\n",
    "\n",
    "# labels = ['Whole matrix', 'Arm 1', 'Arm 2']\n",
    "\n",
    "# for i in range(3):\n",
    "#     ax[0].plot(rest_sequenceness['forwards'][..., 9].mean(axis=0), label=labels[i])\n",
    "# ax[0].set_xlabel('Lag')\n",
    "# ax[0].set_title('Rest sequenceness')\n",
    "# ax[0].set_ylabel(r'Backward $\\leftarrow$ Sequenceness $\\rightarrow$ Forward')\n",
    "# ax[0].legend()\n",
    "\n",
    "# for i in range(3):\n",
    "#     ax[1].plot(planning_sequenceness['backwards'][..., 9].mean(axis=0), label=labels[i])\n",
    "# ax[1].set_xlabel('Lag')\n",
    "# ax[1].set_title('Planning sequenceness')\n",
    "# ax[1].set_ylabel(r'Backward $\\leftarrow$ Sequenceness $\\rightarrow$ Forward')\n",
    "# ax[1].legend();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the sequenceness data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(planning_state_reactivation, os.path.join(output_dir, 'sequenceness', 'planning', 'sub-{0}_planning_sequenceness.pkl'.format(session_id)))\n",
    "joblib.dump(rest_state_reactivation, os.path.join(output_dir, 'sequenceness', 'rest', 'sub-{0}_rest_sequenceness.pkl'.format(session_id)))\n",
    "# joblib.dump(planning_sequenceness, os.path.join(output_dir, 'sequenceness', 'planning', 'sub-{0}_planning_sequenceness.pkl'.format(session_id)))\n",
    "# joblib.dump(rest_sequenceness, os.path.join(output_dir, 'sequenceness', 'rest', 'sub-{0}_rest_sequenceness.pkl'.format(session_id)))\n",
    "# joblib.dump(null_planning_sequenceness, os.path.join(output_dir, 'sequenceness', 'planning', 'sub-{0}_null_planning_sequenceness.pkl'.format(session_id)))\n",
    "# joblib.dump(null_rest_sequenceness, os.path.join(output_dir, 'sequenceness', 'rest', 'sub-{0}_null_rest_sequenceness.pkl'.format(session_id)))\n",
    "# joblib.dump(planning_sequenceness_segments, os.path.join(output_dir, 'sequenceness', 'planning', 'sub-{0}_planning_sequenceness_segments.pkl'.format(session_id)))\n",
    "# joblib.dump(rest_sequenceness_segments, os.path.join(output_dir, 'sequenceness', 'rest', 'sub-{0}_rest_sequenceness_segments.pkl'.format(session_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outcome reactivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_clf = joblib.load(os.path.join(output_dir, 'classifier', 'sub-{0}_outcome_classifier.pkl').format(session_id)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict outcome reactivations for planning, rest, and final state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state_epochs = mne.read_epochs(os.path.join(output_dir, 'preprocessing/task', 'sub-{0}_ses-01_task-AversiveLearningReplay_run-task_final_state_proc_ICA-epo.fif.gz').format(session_id))\n",
    "final_state_X = final_state_epochs.get_data()[:, picks_meg, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_outcome_reactivation = predict_states(rest_X, outcome_clf, n_stim=3)\n",
    "planning_outcome_reactivation = predict_states(planning_X, outcome_clf, n_stim=3)\n",
    "final_state_outcome_reactivation = predict_states(final_state_X, outcome_clf, n_stim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save state probabilities\n",
    "np.save(os.path.join(output_dir, 'outcome_reactivation_arrays', 'planning', 'sub-{0}_planning_outcome_reactivation'.format(session_id)), planning_outcome_reactivation)\n",
    "np.save(os.path.join(output_dir, 'outcome_reactivation_arrays', 'rest', 'sub-{0}_rest_outcome_reactivation'.format(session_id)), rest_outcome_reactivation)\n",
    "np.save(os.path.join(output_dir, 'outcome_reactivation_arrays', 'final_state', 'sub-{0}_final_state_outcome_reactivation'.format(session_id)), final_state_outcome_reactivation)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "psychopy3"
  },
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "mne"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "nteract": {
   "version": "0.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
